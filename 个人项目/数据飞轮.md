# 数据飞轮

## Situation（背景）

构筑一个统一的AI平台CoreMind，承载三大智能：网络智能、业务智能、运维智能训练；网络智能：通过流量识别流量来源、规避流量阻塞等、业务智能：提供数字孪生、通话数字人等、运维智能：自动处理监控网元问题等；

## **Target（目标）**

Coremind数据飞轮，提供一个统一的Coremind平台能力入口供上游（扶摇训练平台）使用

## **Action（行动）**

作为数据飞轮owner，从0到1构筑数据飞轮样机（参考airflow），提供任务流编排调度框架，提供创建任务流能力，并将任务下发到下游服务

### 主要流程

数据飞轮使用go开发，北向提供任务流生命周期管理接口，包括：创建（通过导入任务流定义的yaml）、启动、删除、停止、暂停、重启，南向提供下游服务（训练、数据服务）注册接口，同时具备任务流编排调度引擎，对每个任务流中的任务，按需下发到对应的下游服务；

首先，南向服务实例启动时，会调数据飞轮的南向注册接口，通过传入一个yaml，将每个操作（创建、删除、暂停等）对应的接口，接收什么类型的任务，每个接口会返回什么信息，都注册到数据飞轮服务，数据飞轮会将这些注册信息封装记录到一个全局的map；

调度引擎是一个可配置间隔时间的定时器，每间隔规定秒数执行一次业务逻辑，其运行逻辑使用了策略模式，分为两个策略，一个是刷新任务流实例策略，第二个是下发任务策略；

刷新任务流实例策略是获取当前的任务流实例，对于运行中的任务流，根据任务流实例中的任务实例的状态，刷新任务流状态，任务实例的状态通过调用南向服务接口获取，不同类型的任务实例调用不同的南向服务的查询状态接口；

对于尚未启动的任务流，会判断其中的任务是否具备启动条件（某些任务实例有条件依赖），如果符合条件，则调南向服务接口下发任务，真正地创建任务

调用南向服务的接口时，会根据任务类型、任务动作找到对应的handler的对应方法，比如要创建训练任务，就会调traintaskHandler的execute方法，该方法中会根据南向服务注册的信息获取对应的接口、服务名，然后通过所有服务都集成的一个服务发现框架，根据服务名获取到一个实例的endpoint，然后调该实例的接口

#### 为什么传入yaml

- yaml语法简洁
- 虽然我们最终的交付是作为一个组件和其他平台对接，但是原本的设想并且之后的演进是朝着提供一个数据飞轮前后端，整合成一个独立的Coremind平台，所以使用yaml的话，前端能根据yaml生成数据飞轮的DAG图，以及显式相关的配置，如果之后要添加什么新的配置，前端也不需要修改代码，实现无码化的修改

#### 为什么参考airflow而不是kubeflow

- kubeflow高度依赖k8s和容器编排以及多个组件，对我们的数据飞轮服务来说显得过重
- airflow的任务流定义更清晰
- kubeflow更偏向于事件驱动，由operator（类似自定义controller+crd）监听资源时间并触发处理逻辑，而我们想实现的是跟airflow类似的定时轮询+状态刷新

#### 借鉴了airflow的哪些部分，做了哪些额外创新

1. DAG 定义与依赖建模；
2. TaskInstance 状态流转与调度流程；
3. 定时轮询式调度器设计；
4. 南向服务等价于 Airflow 的 Executor 抽象（对不同类型任务的执行接口抽象）；
5. 任务状态持久化模型（RUNNING、SUCCESS、FAILED、SKIPPED 等状态）也基本参考 Airflow

额外创新：

1. 南向服务注册机制支持下游服务动态扩展



### 难点1

如何确保接口和任务流引擎一致性的问题：

数据飞轮服务提供暂停任务流接口，具体逻辑为：

1. 用户调用暂停接口
2. 数据飞轮遍历任务流的所有任务实例，判断哪些任务是运行中或尚未启动，然后调用对应的南向服务接口暂停南向服务中的任务
3. 然后刷新数据库中，任务流实例和任务实例状态为暂停

但在这个流程中，如果任务流调度引擎恰好在状态写入前执行下发任务策略，会：

1. 查询任务实例，发现尚未启动状态
2. 判断满足启动条件
3. 错误下发任务到南向服务执行

结果导致任务流逻辑上暂停了，但实际仍有任务被下发执行

**解决**

使用版本号+二次确认

1. 每次任务流状态变更时（如暂停），为该任务流生成一个新的状态版本号，存到数据库中，再遍历任务流下发暂停任务
2. 在任务引擎获取任务实例并判断启动条件时，要获取当前的任务流状态版本号
3. 如果判断可执行，在调用南向服务下发任务前，再查询数据库检查一次该任务流的当前版本号是否匹配
4. 若不一致，就跳过下发
5. 下发后，再刷新数据库任务实例的状态

这个方案类似乐观锁，避免了强同步锁带来的性能损耗，同时保证了暂停操作与调度之间的最终一致性

### 难点2

任务流调度引擎每次会查询所有running或initial（尚未启动）状态的任务流实例，再刷新他们的状态，易导致性能瓶颈

**解决**

结合业务考虑，每个任务流实例的状态到下一次变更的间隔一般比较久，因为训练任务、数据处理任务耗时比较长，而一个任务流往往包含数据处理、训练等任务

基于此得到以下方案：

任务流实例增加`next_schedule_time`：下一次调度时间，每次查询

```sql
SELECT * FROM task_flow_instance
WHERE status IN ('RUNNING', 'INITIAL')
  AND next_schedule_time <= now()
```

每次任务流实例刷新后，更新next_schedule_time = now + interval（自适应）

这样下次查询的时候就会错开，防止一次查询很多



## **Result（结果）**

项目最终结果如何？有哪些成就？有哪些不足之处可以改进？

成功上车扶摇平台



