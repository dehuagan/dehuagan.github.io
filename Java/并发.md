# AQS
## 什么是AQS
AQS内部维护一个state状态位，尝试加锁的时候通过CAS(CompareAndSwap)修改值，如果成功设置为1，并且把当前线程ID赋值，则代表加锁成功，一旦获取到锁，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把state重新置为0，同时当前线程ID置为空。

## CAS
CAS叫做CompareAndSwap，比较并交换，主要是通过处理器的指令来保证操作的原子性，它包含三个操作数：

> 1. 变量内存地址，V表示
> 2. 旧的预期值，A表示
> 3. 准备设置的新值，B表示

## CAS缺点
CAS的缺点主要有3点：
> 1. ABA问题：ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。只是ABA的问题大部分场景下都不影响并发的最终效果。
> 
> Java中有AtomicStampedReference来解决这个问题，他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。
> 
> 2. 循环时间长开销大：自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。
> 
> 3. 只能保证一个共享变量的原子操作：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过AtomicReference来处理或者使用锁synchronized实现。


# ThreadLocal

```
ThreadLocal<String> localName = new ThreadLocal();
localName.set("张三");
String name = localName.get();
localName.remove();
```
> 其实使用真的很简单，线程进来之后初始化一个可以泛型的ThreadLocal对象，之后这个线程只要在remove之前去get，都能拿到之前set的值，注意这里我说的是remove之前。

## ThreadLocal例子
> Spring采用Threadlocal的方式，来保证单个线程中的数据库操作使用的是同一个数据库连接，同时，采用这种方式可以使业务层使用事务时不需要感知并管理connection对象，通过传播级别，巧妙地管理多个事务配置之间的切换，挂起和恢复。

# 线程池
## 核心参数
> 1. 核心线程数 corePoolSize
> 2. 最大线程数 maximumPoolSize
> 3. 活跃时间 keepAliveTime
> 4. 阻塞队列 workQueue
> 5. 拒绝策略 RejectedExecutionHandler

## 提交一个新任务到线程池时，具体执行流程：
> 1. 当我们提交任务，线程池会根据corePoolSize大小创建若干任务线程执行任务
> 2. 当任务的数量超过corePoolSize时，后续的任务将会进入阻塞队列阻塞排队
> 3. 当阻塞队列也满了的时候，将会继续创建(maximumPoolSize-corePoolSize)个数量的线程执行任务，如果任务处理完成，maximumPoolSize-corePoolSize额外创建的线程等待keepAliveTime之后被自动销毁
> 4. 如果达到maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理

## 主要有4种拒绝策略
> 1. AbortPolicy：直接丢弃任务，抛出异常，这是默认策略
> 2. CallerRunsPolicy：只用调用者所在的线程来处理任务
> 3. DiscardOldestPolicy：丢弃等待队列中最旧的任务，并执行当前任务
> 4. DiscardPolicy：直接丢弃任务，也不抛出异常

## 阿里JAVA开发手册规定不能用

```
ExecutorService executorService = Executors.newCachedThreadPool();
```
### 弊端
> - FixedThreadPool和SingleThreadExecutor允许请求的队列长度为maxValue，可能堆积大量的请求，导致OOM
> - CachedThreadPool和ScheduledThreadPool允许创建的线程数量为maxValue，可能会创建大量的线程，导致OOM

## 业务实践
### 1. 快速响应用户请求
> - 描述：用户发起的实时请求，服务追求响应时间。比如说用户要查看一个商品的信息，那么我们需要将商品维度的一系列信息如商品的价格、优惠、库存、图片等等聚合起来，展示给用户。
>
> - 分析：从用户体验角度看，这个结果响应的越快越好，如果一个页面半天都刷不出，用户可能就放弃查看这个商品了。而面向用户的功能聚合通常非常复杂，伴随着调用与调用之间的级联、多级级联等情况，业务开发同学往往会选择使用线程池这种简单的方式，将调用封装成任务并行的执行，缩短总体响应时间。另外，使用线程池也是有考量的，这种场景最重要的就是获取最大的响应速度去满足用户，所以应该不设置队列去缓冲并发任务，调高corePoolSize和maxPoolSize去尽可能创造多的线程快速执行任务。

### 2. 快速处理批量任务
> - 描述：离线的大量计算任务，需要快速执行。比如说，统计某个报表，需要计算出全国各个门店中有哪些商品有某种属性，用于后续营销策略的分析，那么我们需要查询全国所有门店中的所有商品，并且记录具有某属性的商品，然后快速生成报表。
>
> - 分析：这种场景需要执行大量的任务，我们也会希望任务执行的越快越好。这种情况下，也应该使用多线程策略，并行计算。但与响应速度优先的场景区别在于，这类场景任务量巨大，并不需要瞬时的完成，而是关注如何使用有限的资源，尽可能在单位时间内处理更多的任务，也就是吞吐量优先的问题。所以应该设置队列去缓冲并发任务，调整合适的corePoolSize去设置处理任务的线程数。在这里，设置的线程数过多可能还会引发线程上下文切换频繁的问题，也会降低处理任务的速度，降低吞吐量。


